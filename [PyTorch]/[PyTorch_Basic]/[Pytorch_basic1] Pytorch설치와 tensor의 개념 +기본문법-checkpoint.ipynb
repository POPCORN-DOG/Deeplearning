{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 글은 YOUTUBE 파이토치 입문 강의를 수강하고 작성한 문서입니다.\n",
    "# https://www.youtube.com/watch?v=6SF_qAd99Yg&t=471s&ab_channel=%EB%94%A5%EB%9F%AC%EB%8B%9D%ED%98%B8%ED%98%95DLbro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CUDA(\"Compute Unified Device Architecture\",쿠다)\n",
    "- 그래픽 처리 장치(GPU)에서 수행하는 (병렬 처리) 알고리즘을 C프로그래밍 언어를 비롯한 \n",
    "산업 표준 언어를 사용하여 작성할 수 있도록 하는 기술이다.(NVIDIA사에서 개발한 GPU개발 툴)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 윈도우 10 CUDA 설치 방법\n",
    "1. TensorFlow와 Pytorch에서 사용가능한 CUDA버전으로 설치하자.\n",
    "2. (https://www.tensorflow.org/install/source_windows#tested_build_configurations)\n",
    "3. (https://pytorch.org/get-started/locally/)\n",
    "4. (https://en.wikipedia.org/wiki/CUDA#Version_features_and_specifications)에서 gpu버전 검색 후 compute capability 버전이 CUDA SDK 10 (or 11 등)을 쓸 수 있는지 없는지 판단5. 지원되는 윈도우 버전 (https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html)에서 표를 참고하여 자신의 윈도우 버전을 지원하는 cuda 버전을 확인한다.\n",
    "6. 지원되는 Microsoft Visual Studio (2번과 같은 페이지 접속 후 확인 가능)\n",
    "- NVIDIA CUDA Toolkit\n",
    "- (tip) pip install tensorflow 설치 후 pip freeze 아나콘다를 통해 깔려있는 모든 것들이 나열."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch의 기본 개념\n",
    "- The torch package contains data structures for multi-dimensional tensors and mathematical operations over these are defined.\n",
    "- Pytorch는 내부적인 CUDA API를 통해 GPU연산을 제공한다. \n",
    "- 최근 Tensorflow를 따라잡는 추세이다.\n",
    "- 논문 대부분이 Pytorch로 구현되며 직관적으로 이해하기 좋다.\n",
    "- tensor를 이용한 연산으로 numpy array와 유사하다.\n",
    "- torch.empty() .size .ones .zeros .rand .view .numpy .tensor .add .add_ .item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # pytorch는 기본적으로 라이브러리로 torch를 사용.\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[9.2755e-39, 1.0561e-38, 9.1837e-39, 9.1837e-39],\n",
      "        [9.9184e-39, 8.9082e-39, 8.9082e-39, 1.0194e-38],\n",
      "        [9.1837e-39, 4.6837e-39, 9.9184e-39, 9.0000e-39],\n",
      "        [1.0561e-38, 1.0653e-38, 4.1327e-39, 8.9082e-39],\n",
      "        [9.8265e-39, 9.4592e-39, 1.0561e-38, 1.0653e-38]]) \n",
      " torch.Size([5, 4])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# 빈 텐서 생성\n",
    "x = torch.empty(5,4) \n",
    "print(x,'\\n',x.size())\n",
    "print(type(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([0., 0.])\n",
      "tensor([[0.9222, 0.2338, 0.4109, 0.1327, 0.7764, 0.5113],\n",
      "        [0.9079, 0.8640, 0.8157, 0.0611, 0.9163, 0.8853],\n",
      "        [0.5412, 0.2925, 0.6277, 0.0185, 0.4605, 0.7447],\n",
      "        [0.3988, 0.8015, 0.4199, 0.2650, 0.8979, 0.1250],\n",
      "        [0.4612, 0.5074, 0.9681, 0.8723, 0.5285, 0.6841]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.ones(3,3)) # 1행렬\n",
    "print(torch.zeros(2)) # 영행렬\n",
    "print(torch.rand(5,6)) # 랜덤함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 4]\n",
      "tensor([13,  4])\n",
      "[ 4 56  7]\n",
      "tensor([ 4, 56,  7], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# 만약 리스트나 어레이가 주어진다면?\n",
    "l = [13,4] \n",
    "r = np.array([4,56,7])\n",
    "\n",
    "# pytorch의 기본단위는 tensor기 때문에 이와같이 변환해야한다. 편함\n",
    "print(l)\n",
    "print(torch.tensor(l))\n",
    "print(r)\n",
    "print(torch.tensor(r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor([[0.2710, 0.5095],\n",
      "        [0.0356, 0.3879]])\n",
      "y: tensor([[0.8872, 0.3657],\n",
      "        [0.2630, 0.5088]])\n",
      "일반수식 합게: tensor([[1.1582, 0.8752],\n",
      "        [0.2987, 0.8966]])\n",
      "함수이용 합계: tensor([[1.1582, 0.8752],\n",
      "        [0.2987, 0.8966]])\n",
      "y에 x를 더함: tensor([[1.1582, 0.8752],\n",
      "        [0.2987, 0.8966]])\n",
      "y변수 대체 inplace방식: tensor([[1.1582, 0.8752],\n",
      "        [0.2987, 0.8966]])\n",
      "x+y를 더한 y변수: tensor([[1.1582, 0.8752],\n",
      "        [0.2987, 0.8966]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,2)\n",
    "y = torch.rand(2,2)\n",
    "print('x:',x)\n",
    "print('y:',y)\n",
    "print('일반수식 합게:',  x+y)\n",
    "print('함수이용 합계:',  torch.add(x,y))\n",
    "print('y에 x를 더함:',  y.add(x))\n",
    "print('y변수 대체 inplace방식:',  y.add_(x))\n",
    "print('x+y를 더한 y변수:',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9605103 , 0.5307135 , 0.36437595, 0.8242474 , 0.5166813 ,\n",
       "       0.6684228 , 0.946142  , 0.4315912 ], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python의 0부터 시작하는 특성상 tensor([[0,1],[0,1])\n",
    "y[1,1] \n",
    "y[:,1] #행 열이기 때문에 1열 표현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# view함수\n",
    "- cnn인 경우 convolution layer를 연산하다가 \n",
    "- free conected layer로 들어갈 때 정사각형 이미지를 일렬로 펼 때 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4916, 0.9605, 0.2899, 0.4958, 0.8783, 0.2349, 0.9609, 0.9666],\n",
      "        [0.7329, 0.5307, 0.1593, 0.6619, 0.1982, 0.0754, 0.7795, 0.3243],\n",
      "        [0.7747, 0.3644, 0.0171, 0.1184, 0.4983, 0.7587, 0.2751, 0.9298],\n",
      "        [0.1907, 0.8242, 0.3661, 0.0407, 0.6432, 0.2059, 0.7039, 0.9737],\n",
      "        [0.5827, 0.5167, 0.6504, 0.2131, 0.8573, 0.4596, 0.0873, 0.6071],\n",
      "        [0.0317, 0.6684, 0.0923, 0.5369, 0.3113, 0.8494, 0.7532, 0.0993],\n",
      "        [0.8778, 0.9461, 0.1372, 0.5115, 0.0853, 0.2598, 0.0425, 0.7606],\n",
      "        [0.0641, 0.4316, 0.3820, 0.1347, 0.0243, 0.0129, 0.0549, 0.5437]])\n"
     ]
    }
   ],
   "source": [
    "# view함수(사이즈를 자유롭게 바꿀 수 있다.)\n",
    "x = torch.rand(8,8)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4916, 0.9605, 0.2899, 0.4958, 0.8783, 0.2349, 0.9609, 0.9666, 0.7329,\n",
       "        0.5307, 0.1593, 0.6619, 0.1982, 0.0754, 0.7795, 0.3243, 0.7747, 0.3644,\n",
       "        0.0171, 0.1184, 0.4983, 0.7587, 0.2751, 0.9298, 0.1907, 0.8242, 0.3661,\n",
       "        0.0407, 0.6432, 0.2059, 0.7039, 0.9737, 0.5827, 0.5167, 0.6504, 0.2131,\n",
       "        0.8573, 0.4596, 0.0873, 0.6071, 0.0317, 0.6684, 0.0923, 0.5369, 0.3113,\n",
       "        0.8494, 0.7532, 0.0993, 0.8778, 0.9461, 0.1372, 0.5115, 0.0853, 0.2598,\n",
       "        0.0425, 0.7606, 0.0641, 0.4316, 0.3820, 0.1347, 0.0243, 0.0129, 0.0549,\n",
       "        0.5437])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8행 8열의 64개를 한개의 열로 나열하겠다. 열 기준으로 나열된다.\n",
    "# 8*8 = 64개\n",
    "x.view(64) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4916, 0.9605, 0.2899, 0.4958, 0.8783, 0.2349, 0.9609, 0.9666, 0.7329,\n",
       "         0.5307, 0.1593, 0.6619, 0.1982, 0.0754, 0.7795, 0.3243],\n",
       "        [0.7747, 0.3644, 0.0171, 0.1184, 0.4983, 0.7587, 0.2751, 0.9298, 0.1907,\n",
       "         0.8242, 0.3661, 0.0407, 0.6432, 0.2059, 0.7039, 0.9737],\n",
       "        [0.5827, 0.5167, 0.6504, 0.2131, 0.8573, 0.4596, 0.0873, 0.6071, 0.0317,\n",
       "         0.6684, 0.0923, 0.5369, 0.3113, 0.8494, 0.7532, 0.0993],\n",
       "        [0.8778, 0.9461, 0.1372, 0.5115, 0.0853, 0.2598, 0.0425, 0.7606, 0.0641,\n",
       "         0.4316, 0.3820, 0.1347, 0.0243, 0.0129, 0.0549, 0.5437]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 64의 약수들로 표현되기 때문에 4*16으로도 표현 가능하다.\n",
    "# 즉, 4행 16열\n",
    "x.view(4,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4916, 0.9605, 0.2899, 0.4958, 0.8783, 0.2349, 0.9609, 0.9666, 0.7329,\n",
       "         0.5307, 0.1593, 0.6619, 0.1982, 0.0754, 0.7795, 0.3243],\n",
       "        [0.7747, 0.3644, 0.0171, 0.1184, 0.4983, 0.7587, 0.2751, 0.9298, 0.1907,\n",
       "         0.8242, 0.3661, 0.0407, 0.6432, 0.2059, 0.7039, 0.9737],\n",
       "        [0.5827, 0.5167, 0.6504, 0.2131, 0.8573, 0.4596, 0.0873, 0.6071, 0.0317,\n",
       "         0.6684, 0.0923, 0.5369, 0.3113, 0.8494, 0.7532, 0.0993],\n",
       "        [0.8778, 0.9461, 0.1372, 0.5115, 0.0853, 0.2598, 0.0425, 0.7606, 0.0641,\n",
       "         0.4316, 0.3820, 0.1347, 0.0243, 0.0129, 0.0549, 0.5437]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 그러나 항상 약수를 계산해야하는 번거로움이 있기 때문에 \n",
    "# 한쪽값을 원하는 값으로 고정한 채로 -1을 넣어주면 자동값으로 입력된다.\n",
    "# 즉, 여기서의 -1은 4를 뜻하게 된다.\n",
    "x.view(-1,16) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4916, 0.9605, 0.2899, 0.4958],\n",
       "         [0.8783, 0.2349, 0.9609, 0.9666],\n",
       "         [0.7329, 0.5307, 0.1593, 0.6619],\n",
       "         [0.1982, 0.0754, 0.7795, 0.3243]],\n",
       "\n",
       "        [[0.7747, 0.3644, 0.0171, 0.1184],\n",
       "         [0.4983, 0.7587, 0.2751, 0.9298],\n",
       "         [0.1907, 0.8242, 0.3661, 0.0407],\n",
       "         [0.6432, 0.2059, 0.7039, 0.9737]],\n",
       "\n",
       "        [[0.5827, 0.5167, 0.6504, 0.2131],\n",
       "         [0.8573, 0.4596, 0.0873, 0.6071],\n",
       "         [0.0317, 0.6684, 0.0923, 0.5369],\n",
       "         [0.3113, 0.8494, 0.7532, 0.0993]],\n",
       "\n",
       "        [[0.8778, 0.9461, 0.1372, 0.5115],\n",
       "         [0.0853, 0.2598, 0.0425, 0.7606],\n",
       "         [0.0641, 0.4316, 0.3820, 0.1347],\n",
       "         [0.0243, 0.0129, 0.0549, 0.5437]]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -1은 나머지 값이 고정된 상태여야하기 때문에 3차원을 할 때에도 하나만!\n",
    "# x.view(-1,4,-1)\n",
    "x.view(-1,4,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# item함수\n",
    "## + tensor -> numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.49163198 0.9605103  0.28987586 0.49578196 0.8782502  0.23485643\n",
      "  0.9608764  0.9666484 ]\n",
      " [0.7329183  0.5307135  0.1592738  0.66188097 0.1981759  0.07535726\n",
      "  0.77948064 0.32429302]\n",
      " [0.774681   0.36437595 0.01714456 0.11840898 0.49825174 0.75873154\n",
      "  0.27512968 0.9298188 ]\n",
      " [0.19070989 0.8242474  0.36610013 0.04074872 0.6432078  0.20592713\n",
      "  0.70392466 0.9737031 ]\n",
      " [0.58272856 0.5166813  0.65035725 0.21305364 0.8572848  0.45961958\n",
      "  0.08728683 0.60714364]\n",
      " [0.03172988 0.6684228  0.09226149 0.5368738  0.31128192 0.84941053\n",
      "  0.75323695 0.0993439 ]\n",
      " [0.8778057  0.946142   0.13716722 0.5114643  0.08530354 0.25983524\n",
      "  0.04247302 0.76058394]\n",
      " [0.06412882 0.4315912  0.38198978 0.13472599 0.024288   0.01288879\n",
      "  0.05491626 0.5437192 ]] <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# 매우 간단함. 이 방법 외에도 많이 있다.\n",
    "y = x.numpy()\n",
    "print(y,type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# 마지막으로 많이 쓰이는게 item이라는 함수인데 tensor가 scala일 경우(원소가 1개)만 사용 가능함\n",
    "# 텐서 안의 값을 정수나 실수의 숫자형태로 불러오고 싶을 때 사용\n",
    "# x 자체는 값이 아니고 텐서니까 값을 뽑아내려면 item을 사용\n",
    "# loss값이 대표되는 단일값(scala값)으로 나오는데 floating할 떄 등등 사용...\n",
    "x = torch.ones(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
