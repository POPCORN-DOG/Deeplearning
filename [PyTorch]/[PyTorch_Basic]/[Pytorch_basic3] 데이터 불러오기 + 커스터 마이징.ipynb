{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이 글은 YOUTUBE 파이토치 입문 강의를 수강하고 작성한 문서입니다.\n",
    "# https://www.youtube.com/watch?v=8PnxJ3s3Cwo&t=888s&ab_channel=%EB%94%A5%EB%9F%AC%EB%8B%9D%ED%98%B8%ED%98%95DLbro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(요약)\n",
    "### 1. 파이토치 제공 데이터 사용\n",
    "### 2. 같은 클래스 별 폴더 이미지 데이터 이용\n",
    "### 3. 개인 데이터 사용 (2 types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import torchvision.transforms as tr \n",
    "# torchvision.transforms: 데이터를 불러오면서 전처리를 바로 할 수 있도록 해준다.\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "# DataLoader: 배치사이즈 형태로 만들어서 실제로 학습을 할 떄 이용할 수 있는 형태로 만들어주는 라이브러리\n",
    "# Dataset: 튜닝 할 때 사용 \n",
    "import numpy as np\n",
    "\n",
    "#import pandas as pd\n",
    "#print(\"pandas version: \", pd.__version__)\n",
    "#pd.set_option('display.max_row', 500000)\n",
    "#pd.set_option('display.max_columns', 100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 파이토치 제공 데이터 사용\n",
    "- 많은 데이터가 있으며 그 중 원하는 것으로 파일명을 적으면 된다. \n",
    "- 실제 논문에서 많이 사용되는 데이터이기 때문에 신뢰성이 높다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 사이트에 가면 여러가지 정의가 있다.\n",
    "# 그 중에 필요한 전처리 작업을 일렬로 compose안에 나열해주자.\n",
    "# compose: 전처리를 할 때 순서대로 작업을 처리하게 된다.\n",
    "# 지금의 경우는 8 by 8 로 resize가 되고, tensor데이터로 바꿔준다는 뜻\n",
    "transf = tr.Compose([tr.Resize(8),tr.ToTensor()])\n",
    "\n",
    "# Transforms on PIL Image \n",
    "# ***(주의)처음의 이미지는 PIL 이미지라고 해서 특정 타입을 이야기한다. 여기서 이 부분 주의하자. \n",
    "# numpy, list transform에 넣어주면 오류가 난다. 즉, PIL 이미지여야 한다.\n",
    "\n",
    "# Pad, Grayscale, RandomCrop, Normalize ..\n",
    "# Transforms on torch.*Tensor - tensor image\n",
    "# torchvision.transforms.ToPILImage(mode=None)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# root: 다운로드를 받을 수 있는 경로\n",
    "# download: 당연히 받아야 한다.\n",
    "# transform: 다운로드를 받고 들어오는 데이터에 대해 전처리를 해주겠다.\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data',train=True, download=True, transform=transf)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data',train=False, download=True, transform=transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 8, 8])\n",
      "tensor([[[0.2275, 0.4510, 0.4667, 0.4745, 0.4745, 0.5098, 0.5255, 0.4824],\n",
      "         [0.4196, 0.4902, 0.4627, 0.3882, 0.4275, 0.4275, 0.4902, 0.3765],\n",
      "         [0.5529, 0.5020, 0.4549, 0.4549, 0.5843, 0.4941, 0.4980, 0.5059],\n",
      "         [0.5608, 0.4235, 0.5765, 0.7804, 0.8510, 0.7765, 0.5922, 0.5176],\n",
      "         [0.5294, 0.5412, 0.7529, 0.7686, 0.7333, 0.7804, 0.6392, 0.5059],\n",
      "         [0.5333, 0.6118, 0.7216, 0.6667, 0.5765, 0.5804, 0.5059, 0.5216],\n",
      "         [0.6196, 0.5765, 0.6196, 0.6157, 0.5569, 0.5294, 0.5255, 0.5922],\n",
      "         [0.7294, 0.6706, 0.5804, 0.5608, 0.5647, 0.5294, 0.4667, 0.4863]],\n",
      "\n",
      "        [[0.1529, 0.3059, 0.3255, 0.3294, 0.3333, 0.3686, 0.3765, 0.3490],\n",
      "         [0.2784, 0.3176, 0.3059, 0.2431, 0.2627, 0.2784, 0.3255, 0.2471],\n",
      "         [0.4039, 0.3529, 0.3020, 0.2863, 0.3608, 0.3294, 0.3333, 0.3490],\n",
      "         [0.4118, 0.2902, 0.4118, 0.6314, 0.7333, 0.6627, 0.4588, 0.3725],\n",
      "         [0.3647, 0.4118, 0.6314, 0.6431, 0.6392, 0.7059, 0.5294, 0.3922],\n",
      "         [0.3529, 0.4627, 0.5843, 0.5098, 0.4196, 0.4510, 0.4392, 0.4706],\n",
      "         [0.4314, 0.4039, 0.4471, 0.4588, 0.3843, 0.3686, 0.4196, 0.4941],\n",
      "         [0.5686, 0.5216, 0.4157, 0.3843, 0.3882, 0.3608, 0.3412, 0.3686]],\n",
      "\n",
      "        [[0.0902, 0.1725, 0.1961, 0.1922, 0.1882, 0.2157, 0.2314, 0.2235],\n",
      "         [0.1451, 0.1608, 0.1569, 0.1137, 0.1451, 0.1882, 0.2000, 0.1333],\n",
      "         [0.2627, 0.2118, 0.1608, 0.1608, 0.2314, 0.2157, 0.1882, 0.2000],\n",
      "         [0.2627, 0.1765, 0.2510, 0.4588, 0.5608, 0.4941, 0.3020, 0.2078],\n",
      "         [0.2157, 0.2941, 0.5059, 0.5098, 0.5020, 0.5529, 0.3176, 0.1412],\n",
      "         [0.1961, 0.3176, 0.4510, 0.3490, 0.2353, 0.2902, 0.1882, 0.1647],\n",
      "         [0.1686, 0.2157, 0.2980, 0.3098, 0.2275, 0.1961, 0.1961, 0.2471],\n",
      "         [0.1922, 0.1804, 0.2196, 0.2353, 0.2431, 0.1961, 0.1961, 0.2235]]])\n"
     ]
    }
   ],
   "source": [
    "# 트레이닝 셋의 사이즈를 보자.\n",
    "# 튜플형태로 들어가 있다.\n",
    "# 첫번째로 이미지 그 옆으로는 레이블이 들어가 있다.\n",
    "print(trainset[0][0].size())\n",
    "print(trainset[0][0])\n",
    "# 의미: 채널 3개의 8 x 8짜리 이미지다.\n",
    "# CIFAR10이 RGB채널이라 3채널이 된다. \n",
    "\n",
    "# 일반적으로 이미지는 이미지 크기와 그 뒤에 채널 갯수가 붙게 된다. \n",
    "# 그래서 PYTHON이나 OpenCV(Open Source Computer Vision) 이런 것들을 이용할 떄 \n",
    "# ([8, 8, 3])으로 표현되어 있다. 파이토치는 다름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 셋을 받아서 이용할 수 있는 배치 형태로 만들어 보자.\n",
    "# num_workers: 데이터를 로드할 때 프로세스를 몇개 쓰느냐. ex)0, 2, 4...\n",
    "# 데이터 로더를 통해서 배치형태로 전부 분리 상태. \n",
    "# 후 테스트 로더를 통해서 인공신경망에 바로 사용 가능.\n",
    "trainloader = DataLoader(trainset, batch_size=50, shuffle=True, num_workers=2)\n",
    "testloader = DataLoader(testset, batch_size=50, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CIFAR10 데이터의 트레이닝 이미지 개수가 50,000개이기 때문에 batch_size=50을 설정하면\n",
    "# batch_size=50개 짜리가 1000개가 있다는 뜻.\n",
    "# 확인해보면 50,000개를 잘 나눈다면 데이터 로더의 길이가 1000이다.\n",
    "len(trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iter(), next(): trainloader의 실제 값을 보기 위한 함수\n",
    "# iter : 하나씩 불러오겠다.\n",
    "# .next(): 한 묶음에 대해서 불러 온다고 생각하자.\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader._MultiProcessingDataLoaderIter object at 0x000001277A8580D0>\n",
      "tensor([[0.6118, 0.6314, 0.6588, 0.6706, 0.6667, 0.6549, 0.6353, 0.6118],\n",
      "        [0.6078, 0.6078, 0.6980, 0.7137, 0.7137, 0.6980, 0.6824, 0.6627],\n",
      "        [0.5882, 0.5333, 0.6863, 0.7294, 0.7451, 0.7373, 0.7216, 0.7020],\n",
      "        [0.5843, 0.4314, 0.4588, 0.6039, 0.7412, 0.7608, 0.7451, 0.7294],\n",
      "        [0.5686, 0.3255, 0.2980, 0.3961, 0.6157, 0.7490, 0.7451, 0.7333],\n",
      "        [0.6392, 0.5255, 0.4549, 0.4588, 0.5176, 0.6667, 0.7098, 0.7176],\n",
      "        [0.6706, 0.6784, 0.6863, 0.6745, 0.6431, 0.6078, 0.5804, 0.6471],\n",
      "        [0.6627, 0.6784, 0.6941, 0.7020, 0.7020, 0.6902, 0.6667, 0.6667]])\n",
      "tensor([0, 4, 9, 0, 7, 8, 7, 4, 3, 3, 5, 9, 9, 4, 3, 5, 2, 8, 5, 4, 0, 8, 3, 8,\n",
      "        7, 8, 5, 9, 9, 6, 2, 9, 3, 6, 7, 6, 6, 0, 0, 6, 2, 5, 7, 6, 5, 2, 3, 9,\n",
      "        9, 8])\n"
     ]
    }
   ],
   "source": [
    "print(dataiter)\n",
    "print(images[0][0])\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 8, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 항상 파이토치는 신경망에 들어갈 떄 이 순서이다. 잘 기억하자.\n",
    "# batch_size가 50, 채널 3개, 이미지 너비가 8, 높이가 8\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 같은 클래스별 폴더 이미지 데이터 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코드가 있는 폴더에 class폴더를 만들고 그 안에 클래스마다 폴더 생성 후 이미지를 넣어야한다.\n",
    "# 원하는 이미지를 사용할 수 있도록 하는 방법이다.\n",
    "\n",
    "# 정리를 잘 해서 이미지 데이터를 폴더 안에 class 별로 다 나눠놓은 경우...\n",
    "# ./class/tiger(이미지A)   ./class/lion(이미지B)\n",
    "# 예를 들어 위와 같이 class 폴더 안에 tiger 폴더와 lion 폴더가 있다.\n",
    "# 폴더가 깔끔하게 나눠진 상태에서 torchvision.datasets.ImageFolder를 사용하여 \n",
    "# root='./class' 폴더 안의 이미지를 알아서 search해 주고 각각의 다른 폴더에 대한\n",
    "# 레이블링을 다르게 자동으로 입력해준다. (+transform을 통해 전처리도 이용가능)\n",
    "# 이미지 명과 관계없이 폴더와 파일 정리만 잘 해주면 알파벳 순으로 들어온다.\n",
    "# 즉 한 줄로 데이터 전체를 불러오고 레이블이 자동으로 매겨지면서 전처리까지 가능하다.\n",
    "transf = tr.Compose([tr.Resize(16),tr.ToTensor()])\n",
    "trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)\n",
    "\n",
    "trainset[0][0].size()\n",
    "# ex> torch.Size([3,16,16])\n",
    "# 채널 수 3개이며 Resize(16)이기때문에 16 by 16\n",
    "\n",
    "# 그리고 실제 학슴을 할 수 있게 배치 사이즈 형태로 데이터 로더를 통해 만들자.\n",
    "trainloader = DataLoader(trainset, batch_size=10, shuffle=False, num_workers=2)\n",
    "print(len(trainloader))\n",
    "# ex) 3일경우 batch_size 10 짜리가 3개 즉, 예시로는 30개의 이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 그럼에도 불구하고 개인적으로 torchvision.datasets.ImageFolder를 쓰지 않는 이유\n",
    "\n",
    "- 3번처럼 할 수 있어야하는 이유: 첫번째로 클래스별로 폴더를 나눌 수 있다면 2번처럼<br>\n",
    "transf = tr.Compose([tr.Resize(16),tr.ToTensor()])<br>\n",
    "trainset = torchvision.datasets.ImageFolder(root='./class', transform=transf)<br>\n",
    "trainloader = DataLoader(trainset, batch_size=10, shuffle=False, num_workers=2)<br>\n",
    "불러오고 전처리하고 배치 나누는 것까지 3줄이면 끝낼 수 있다. 하지만 이렇게 만들 수 없는 경우가 있다. <br>\n",
    "<br>\n",
    "- 폴더 정리를 못하는 경우 \n",
    "1. 다른 작업과 공용으로 사용하는 경우  \n",
    "2. 폴더가 아닌 SQL같은 곳에서 넘어오는 경우 함부로 디렉토리를 바꿀 수 없다.\n",
    "\n",
    "- 파이토치에서 제공하는 Transform의 종류가 제한적이다.\n",
    "예를 들어서 openCV같은 경우 종류가 훨씬 많고 직접 이미지 전처리에 대한 함수를 만들어야할 떄가 있다. 이런 디테일한 부분에 대해서 파이토치에서 제공한 전처리 작업은 사용하지 않는다. 그렇기 때문에 데이터 전처리는 모듈을 만들어 놓는다...\n",
    "<br><br>\n",
    "아래의 경우 한줄로 만들어 preprocessing 이라는 다른 파일에서 전처리가 다 되고 넘어온다.<br>\n",
    "즉, tensor로 바꾸기 전에 전처리가 전부 끝나고 나서 바꾸게 된다.<br>\n",
    "train_images, train_labels = preprocessing(train_images, train_labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 개인 데이터 사용 (2 types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 32, 32, 3) \n",
      " (20, 1)\n"
     ]
    }
   ],
   "source": [
    "#import preprocessing\n",
    "\n",
    "# 먼저, numpy형태의 데이터가 들어왔다고 가정하자.\n",
    "# 그래서 32x32짜리 3채널짜리 이미지가 20개 있다고 가정한다.\n",
    "train_images = np.random.randint(256, size=(20,32,32,3))\n",
    "# 숫자 0, 1 그에 따른 레이블 20개가 있다고 가정하자.\n",
    "train_labels = np.random.randint(2, size=(20,1))\n",
    "\n",
    "# preprocessing 이라는 다른 파일에서 전처리가 다 되고 넘어온다.\n",
    "# 즉, tensor로 바꾸기 전에 전처리가 전부 끝나고 나서 바꾸게 된다.\n",
    "#train_images, train_labels = preprocessing(train_images, train_labels)\n",
    "\n",
    "print(train_images.shape,'\\n', train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1. 상속을 받을 클래스를 생성.\n",
    "class TensorData(Dataset):\n",
    "    \n",
    "    # 정형화된 함수 3개\n",
    "    # 외부에서 데이터가 들어오도록 x_data, y_data 설정(없어도 된다.)\n",
    "    # def __init__(self):\n",
    "    def __init__(self, x_data, y_data):\n",
    "        # 데이터를 텐서로 전환 (float, long과 같이 숫자 속성부여)\n",
    "        self.x_data = torch.FloatTensor(x_data)\n",
    "        # permute함수를 활용하여 순서 변환\n",
    "        # 이미지 개수(배치), 채널 수, 이미지 너비, 높이로 맞추자.\n",
    "        self.x_data = self.x_data.permute(0,3,1,2) \n",
    "        self.y_data = torch.LongTensor(y_data)\n",
    "        # 데이터의 개수산출하기\n",
    "        self.len = self.y_data.shape[0]\n",
    "    \n",
    "    # x, y를 튜플 형태로 바깥으로 내보내기 위함\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 생성\n",
    "train_data = TensorData(train_images, train_labels)\n",
    "# 데이터 로더\n",
    "train_loader = DataLoader(train_data, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 순서가 바뀌었음을 보자.\n",
    "train_data[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마찬가지로 iter를 통해 사이즈를 보자\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# batch_size=10, 채널 3개, 이미지 사이즈 32x32\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 꿀팁 방출!\n",
    "# 4. Pytorch로 무조건 전처리하기\n",
    "클래스로 나눠놓지 못한 경우 개인 데이터에 transform 이용하기.<br><br>\n",
    "(이 형태를 하나의 양식이라 생각하고 작업한다.)\n",
    "- import torch.utils.data import Dataset\n",
    "- class MyDataset(Dataset):\n",
    "-- def __init__(self):\n",
    "-- def __getitem__(self, index):\n",
    "-- def __len__(self):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    # transform=None <- 어떠한 명령어를 적용하여 작동하도록\n",
    "    def __init__(self, x_data, y_data, transform=None):\n",
    "        \n",
    "        # 위와 같이 self.x_data = torch.FloatTensor(x_data)로 \n",
    "        # 텐서변환 작업을 하지 않았기 떄문에 numpy형태로 나온다.\n",
    "        self.x_data = x_data\n",
    "        self.y_data = y_data\n",
    "        self.transform = transform\n",
    "        self.len = len(y_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x_data[index], self.y_data[index]\n",
    "        \n",
    "        # 튜플 형태로 내보내기 전에 전처리 작업을 하겠다.\n",
    "        # transform=None이면 작업을 안하고 넘어가는 것이고...\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "# =========================================================\n",
    "# 위의 transform을 메뉴얼로 작성해보자\n",
    "# ==========================================================  \n",
    "# 텐서를 바꿔주는 클래스를 만들어서 위의 self.x_data = torch.FloatTensor(x_data)에서\n",
    "# 텐서를 바꾸지 않고 실제 transform이 연산되는 과정과 똑같이 만들어 보자.\n",
    "# __call__함수를 만들어 sample을 받게끔 하자.\n",
    "\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        # input을 floattensor로 만들고\n",
    "        inputs = torch.FloatTensor(inputs)\n",
    "        # 형태(채널, 이미지 사이즈)를 바꾸기 위해 permute를 쓴다.\n",
    "        inputs = inputs.permute(2,0,1)\n",
    "        # labels은 그냥 텐서로 바꿔주고...\n",
    "        return inputs, torch.LongTensor(labels)\n",
    "    \n",
    "# ==========================================================\n",
    "# 이제 어떤 연산을 한다... nomalization도 그렇고 ..\n",
    "# 만약 어떤 데이터가 들어오면 거기에 어떤 상수를 곱하고 상수를 더하는 형태를 만들고 싶을 떄\n",
    "# slop와 bias를 정해져서 받을 수 있도록 init에 세팅하고 \n",
    "# 샘플 불러올 수 있게 call함수를 적어야 한다.\n",
    "# ==========================================================\n",
    "class LinearTensor:\n",
    "    \n",
    "    def __init__(self, slope=1, bias=0):\n",
    "        self.slope = slope\n",
    "        self.bias = bias\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, labels = sample\n",
    "        inputs = self.slope*inputs + self.bias\n",
    "        \n",
    "        return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용방법 똑같다. \n",
    "# compose를 통해 지정한다.\n",
    "# 헷갈리지말자. \n",
    "# 앞전의 ToTensor는 tr.ToTensor로써 torchvision.transform의 함수를 사용하는 것 \n",
    "trans = tr.Compose([ToTensor(),LinearTensor(2,5)])\n",
    "ds1 = MyDataset(train_images, train_labels, transform=trans)\n",
    "train_loader1 = DataLoader(ds1, batch_size=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_data = ds1[0]\n",
    "features, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
